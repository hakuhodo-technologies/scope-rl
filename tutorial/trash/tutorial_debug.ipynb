{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import check_random_state\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "\n",
    "\n",
    "from d3rlpy.algos import SAC\n",
    "from d3rlpy.algos import DoubleDQN as DDQN\n",
    "from d3rlpy.algos import CQL\n",
    "from d3rlpy.algos import IQL\n",
    "from d3rlpy.algos import BCQ\n",
    "from d3rlpy.algos import DiscreteCQL\n",
    "from d3rlpy.algos import DiscreteBCQ\n",
    "from d3rlpy.online.explorers import LinearDecayEpsilonGreedy, ConstantEpsilonGreedy\n",
    "from d3rlpy.models.encoders import VectorEncoderFactory\n",
    "from d3rlpy.models.q_functions import MeanQFunctionFactory\n",
    "from d3rlpy.online.buffers import ReplayBuffer\n",
    "\n",
    "from scope_rl.dataset import SyntheticDataset\n",
    "from scope_rl.policy import BaseHead\n",
    "from scope_rl.policy import GaussianHead\n",
    "from scope_rl.policy import EpsilonGreedyHead\n",
    "from scope_rl.policy import SoftmaxHead\n",
    "from scope_rl.policy import TrainCandidatePolicies\n",
    "\n",
    "from scope_rl.ope.online import visualize_on_policy_policy_value\n",
    "from scope_rl.ope.online import calc_on_policy_policy_value\n",
    "\n",
    "from scope_rl.utils import MinMaxActionScaler\n",
    "from scope_rl.utils import OldGymAPIWrapper\n",
    "from scope_rl.types import LoggedDataset\n",
    "\n",
    "from experiments.utils import torch_seed, format_runtime\n",
    "\n",
    "from basicgym import BasicEnv\n",
    "\n",
    "from tutorial.function import train_behavior_policy\n",
    "from tutorial.function import obtain_logged_dataset\n",
    "from tutorial.function import train_candidate_policies\n",
    "# from experiments.main import off_policy_evaluation\n",
    "from tutorial.function import off_policy_evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(\n",
    "    bias_result_df,\n",
    "    variance_result_df,\n",
    "    mse_result_df,\n",
    "    estimators,\n",
    "    ESTIMATORS,\n",
    "    x_scales,\n",
    "    x_label,\n",
    "    yscale_log = False,\n",
    "    xscale_log = False,\n",
    "):\n",
    "\n",
    "    color_dict = {\n",
    "        \"red\": \"#E24A33\",\n",
    "        \"blue\": \"#348ABD\",\n",
    "        \"purple\": \"#988ED5\",\n",
    "        \"gray\": \"#777777\",\n",
    "        \"green\": \"#8EBA42\",\n",
    "        \"yellow\": \"#FBC15E\",\n",
    "        \"pink\": \"#FFB5B8\",\n",
    "        \"brown\": \"#8c564b\",\n",
    "        \"light blue\": \"#17becf\",\n",
    "        \"olive\": \"#bcbd22\",\n",
    "    }\n",
    "    cd = color_dict\n",
    "\n",
    "    plt.style.use(\"ggplot\")\n",
    "    colors = [cd[\"red\"], cd[\"blue\"], cd[\"purple\"], cd[\"gray\"], cd[\"yellow\"], cd['green'], cd['pink'], cd['brown'], cd['light blue'], cd['olive']]\n",
    "    # plt.rcParams[\"axes.prop_cycle\"] = cycler(color=colors)\n",
    "    markers = [\"o\", \"v\", \"^\", \"s\", \"p\", \"P\", \"*\", \"h\", \"X\", \"D\", \"d\"]\n",
    "    # colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    n_colors = len(colors)\n",
    "\n",
    "    log_dir=\"../tutorial/logs_epsilon=0.5/\"\n",
    "\n",
    "    metric_list = ['bias', 'variance', 'mse']\n",
    "\n",
    "    for metric in metric_list:\n",
    "        plt.style.use('ggplot')\n",
    "        fig, ax = plt.subplots(figsize=(10, 7), tight_layout=True)\n",
    "        if metric =='bias':\n",
    "            result_df = bias_result_df\n",
    "        elif metric == 'variance':\n",
    "            result_df = variance_result_df\n",
    "        else:\n",
    "            result_df = mse_result_df\n",
    "\n",
    "        for i, estimator in enumerate(estimators):\n",
    "            data = result_df[result_df['est']==estimator]\n",
    "            data = data.query(f\"({min(x_scales)}<= {x_label} <= {max(x_scales)})\")\n",
    "            ax.plot(\n",
    "                np.array([200, 400, 800, 1600, 3200, 4800, 6400, 8000]),\n",
    "                data[metric],\n",
    "                color=colors[i],\n",
    "                marker=markers[i],\n",
    "                label=ESTIMATORS[i],\n",
    "            )\n",
    "            \n",
    "            ax.legend(ESTIMATORS, loc=\"upper right\", fontsize=20)\n",
    "\n",
    "            ax.fill_between(\n",
    "                np.array([200, 400, 800, 1600, 3200, 4800, 6400, 8000]),\n",
    "                data['lower'],\n",
    "                data['upper'],\n",
    "                color=colors[i % n_colors],\n",
    "                alpha=0.3,\n",
    "                label='',\n",
    "            )\n",
    "\n",
    "        # title and legend\n",
    "        ax.legend(loc=\"upper right\", fontsize=20)\n",
    "        # yaxis\n",
    "        if yscale_log:\n",
    "            ax.set_yscale(\"log\")\n",
    "        ax.set_ylabel(metric, fontsize=25)\n",
    "        ax.tick_params(axis=\"y\", labelsize=15)\n",
    "        ax.yaxis.set_label_coords(-0.08, 0.5)\n",
    "        # xaxis\n",
    "        if xscale_log:\n",
    "            ax.set_xscale(\"log\")\n",
    "        ax.set_xlabel(f\"number of {x_label}\", fontsize=25)\n",
    "        ax.set_xticks(x_scales)\n",
    "        ax.set_xticklabels(x_scales, fontsize=15)\n",
    "        ax.xaxis.set_label_coords(0.5, -0.1)\n",
    "\n",
    "        path_ = Path(log_dir + \"results/fig\")\n",
    "        path_.mkdir(exist_ok=True, parents=True)\n",
    "        save_path = Path(path_ / f\"{metric}_result_fig_{x_label}_{ESTIMATORS}.png\")\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    variable_name,\n",
    "    n_random_state,\n",
    "    log_dir=\"../tutorial/logs/\",\n",
    "    behavior_tau = 1.0,\n",
    "    candidate_epsilons = [1.0],\n",
    "    behavior_sigma = 1.0,\n",
    "    candidate_sigmas = [1.0],\n",
    "    action_type = 'discrete',\n",
    "):\n",
    "    #discrete\n",
    "    env_name=\"BasicEnv-discrete-v0\"\n",
    "    action_type='discrete'\n",
    "    behavior_policy_name=f\"ddqn_softmax_{behavior_tau}\"\n",
    "    candidate_policy_name=f\"cql_eps_{candidate_epsilons[0]}\"\n",
    "\n",
    "    #continuous\n",
    "    # env_name=\"BasicEnv-continuous-v0\"\n",
    "    # action_type='continuous'\n",
    "    # behavior_policy_name=f\"sac_gauss_{behavior_sigma}\"\n",
    "    # candidate_policy_name=f\"cql_b1_gauss_{candidate_sigmas}\"\n",
    "\n",
    "    base_random_state=12345\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    step_per_trajectory_list =  [5, 10, 20, 40, 60, 80, 100]\n",
    "    step_per_trajectory = 10\n",
    "    n_trajectories_list=[200, 400, 800, 1600, 3200, 4800, 6400, 8000]\n",
    "    n_trajectories=1000\n",
    "    n_actions_list = [2, 4, 6, 10, 12, 14]\n",
    "    n_actions=5\n",
    "    \n",
    "    bias_df_list = []\n",
    "    variance_df_list = []\n",
    "    mse_df_list = []\n",
    "\n",
    "    random_ = check_random_state(base_random_state)\n",
    "    n_bootstrap_samples = 100\n",
    "    alpha=0.05\n",
    "    # alpha=0.0\n",
    "\n",
    "    if variable_name == 'n_trajectories':\n",
    "        variable_list = n_trajectories_list\n",
    "    elif variable_name == 'n_actions':\n",
    "        variable_list = n_actions_list\n",
    "    elif variable_name == 'step_per_trajectory':\n",
    "        variable_list = step_per_trajectory_list\n",
    "    else:\n",
    "        ValueError\n",
    "\n",
    "    variable_list = [400]\n",
    "    for variable in variable_list:\n",
    "\n",
    "        if variable_name == 'n_trajectories':\n",
    "            n_trajectories = variable\n",
    "        elif variable_name == 'n_actions':\n",
    "            n_actions == variable\n",
    "        elif variable_name == 'step_per_trajectory':\n",
    "            step_per_trajectory =variable\n",
    "\n",
    "        env = BasicEnv(\n",
    "            action_type=action_type, \n",
    "            n_actions=n_actions,\n",
    "            random_state=base_random_state, \n",
    "            step_per_episode=step_per_trajectory,\n",
    "        )\n",
    "\n",
    "        behavior_policy = train_behavior_policy(\n",
    "            env_name=env_name,\n",
    "            env=env,\n",
    "            behavior_sigma=behavior_sigma,\n",
    "            behavior_tau=behavior_tau,\n",
    "            device=device,\n",
    "            base_random_state=base_random_state,\n",
    "            log_dir=log_dir,\n",
    "            variable=variable,\n",
    "            variable_name=variable_name,\n",
    "        )\n",
    "\n",
    "        train_logged_dataset, test_logged_dataset = obtain_logged_dataset(\n",
    "            env_name=env_name,\n",
    "            env=env,\n",
    "            behavior_policy=behavior_policy,\n",
    "            n_trajectories=n_trajectories,\n",
    "            n_random_state=n_random_state,\n",
    "            base_random_state=base_random_state,\n",
    "            log_dir=log_dir,\n",
    "            variable=variable,\n",
    "            variable_name=variable_name,\n",
    "        )\n",
    "\n",
    "        candidate_policies = train_candidate_policies(\n",
    "            env_name=env_name,\n",
    "            env=env,\n",
    "            n_trajectories=n_trajectories,\n",
    "            train_logged_dataset=train_logged_dataset,\n",
    "            candidate_sigmas=candidate_sigmas,\n",
    "            candidate_epsilons=candidate_epsilons,\n",
    "            device=device,\n",
    "            base_random_state=base_random_state,\n",
    "            log_dir=log_dir,\n",
    "            variable=variable,\n",
    "            variable_name=variable_name,\n",
    "        )\n",
    "\n",
    "        input_dict, policy_value_dict = off_policy_evaluation(\n",
    "            env_name=env_name,\n",
    "            env=env,\n",
    "            n_trajectories=n_trajectories,\n",
    "            test_logged_dataset=test_logged_dataset,\n",
    "            candidate_policies=candidate_policies,\n",
    "            device=device,\n",
    "            base_random_state=base_random_state,\n",
    "            log_dir=log_dir,\n",
    "            variable=variable,\n",
    "            variable_name=variable_name,\n",
    "        )\n",
    "\n",
    "        input_dict_ = input_dict.get(\n",
    "            behavior_policy_name=behavior_policy_name,\n",
    "            dataset_id=0,\n",
    "        )\n",
    "\n",
    "        dict = {i : DataFrame() for i in input_dict_.keys()}\n",
    "        bias_dict = {i : 0 for i in input_dict_.keys()}\n",
    "        variance_dict = {i : 0 for i in input_dict_.keys()}\n",
    "        mse_dict = {i : 0 for i in input_dict_.keys()}\n",
    "        lower_bias = []\n",
    "        mean_bias = []\n",
    "        upper_bias = []\n",
    "        lower_variance = []\n",
    "        mean_variance = []\n",
    "        upper_variance = []\n",
    "        lower_mse = []\n",
    "        mean_mse = []\n",
    "        upper_mse = []\n",
    "\n",
    "        for dataset_id_ in range(n_random_state):\n",
    "            for eval_policy in input_dict_.keys():\n",
    "                dict[eval_policy] = pd.concat([dict[eval_policy] , DataFrame(policy_value_dict[behavior_policy_name][dataset_id_][eval_policy], index=[dataset_id_])])\n",
    "\n",
    "        for eval_policy in input_dict_.keys():\n",
    "            bias_dict[eval_policy] = abs(dict[eval_policy].mean(axis=0) - dict[eval_policy].mean(axis=0)['on_policy'])\n",
    "            # bias_dict[eval_policy] = abs(dict[eval_policy].mean(axis=0))\n",
    "            variance_dict[eval_policy] = dict[eval_policy].var(axis=0)\n",
    "            # print(dict[eval_policy]['tis'])\n",
    "            # print('dict[eval_policy].var(axis=0)', dict[eval_policy].var(axis=0))\n",
    "            mse_dict[eval_policy] = bias_dict[eval_policy]**2 + variance_dict[eval_policy]\n",
    "        \n",
    "        # print(dict[eval_policy]['dm'])\n",
    "        # samples=dict[eval_policy]['tis']\n",
    "        # print(samples)\n",
    "        # print([np.mean(random_.choice(samples, size=samples.shape[0])) for i in range(100)])\n",
    "        # print([np.mean(random_.choice(samples - dict[eval_policy].mean(axis=0)['on_policy'], size=samples.shape[0])) for i in range(100)])\n",
    "        # print('dict[eval_policy].mean(axis=0)[on_policy]', dict[eval_policy].mean(axis=0)['on_policy'])\n",
    "        # print('dict[eval_policy].[on_policy]mean(axis=0)', dict[eval_policy]['on_policy'].mean(axis=0))\n",
    "\n",
    "        for estimator in dict[eval_policy].columns.values:\n",
    "            samples = dict[eval_policy][estimator]\n",
    "            # print('samples', samples)\n",
    "            # print('samples.var', samples.var(axis=0))\n",
    "            # print(samples)\n",
    "            # samples = np.nan_to_num(samples, posinf=1e2)\n",
    "            # samples = np.clip(samples, 0.0, 1e2)\n",
    "            # print('random_choice',random_.choice(samples - dict[eval_policy].mean(axis=0)['on_policy'], size=samples.shape[0]))\n",
    "            # print('np.mean')\n",
    "            # print(np.mean(random_.choice(samples - dict[eval_policy].mean(axis=0)['on_policy'], size=samples.shape[0])))\n",
    "\n",
    "            # print('bootstrap')\n",
    "            # print([np.mean(random_.choice(samples - dict[eval_policy].mean(axis=0)['on_policy'], size=samples.shape[0]))\n",
    "            #     for i in range(5)])\n",
    "\n",
    "            # boot_samples_bias = [\n",
    "            #     np.mean(random_.choice(samples , size=samples.shape[0]))\n",
    "            #     for i in range(n_bootstrap_samples)\n",
    "            # ]\n",
    "\n",
    "            boot_samples_bias = [\n",
    "                np.mean(random_.choice(samples - dict[eval_policy].mean(axis=0)['on_policy'], size=samples.shape[0]))\n",
    "                for i in range(n_bootstrap_samples)\n",
    "            ]\n",
    "            # print(boot_samples_bias)\n",
    "            boot_samples_bias = list(map(abs, boot_samples_bias))\n",
    "            boot_samples_variance = [\n",
    "                np.var(random_.choice(samples, size=samples.shape[0]))\n",
    "                for i in range(n_bootstrap_samples)\n",
    "            ]\n",
    "            print('random_.choice(samples, size=samples.shape[0])', random_.choice(samples, size=samples.shape[0]))\n",
    "            # print()\n",
    "\n",
    "            # print('np.var(random_.choice(samples, size=samples.shape[0]))', np.var(random_.choice(samples, size=samples.shape[0])))\n",
    "            # print(boot_samples_variance)\n",
    "            boot_samples_mse = np.square(boot_samples_bias) + boot_samples_variance\n",
    "\n",
    "            lower_bias.append(np.percentile(boot_samples_bias, 100 * (alpha / 2)))\n",
    "            mean_bias.append(np.percentile(boot_samples_bias, 50))\n",
    "            upper_bias.append(np.percentile(boot_samples_bias, 100 * (1.0 - alpha / 2)))\n",
    "            lower_variance.append(np.percentile(boot_samples_variance, 100 * (alpha / 2)))\n",
    "            mean_variance.append(np.percentile(boot_samples_variance, 50))\n",
    "            upper_variance.append(np.percentile(boot_samples_variance, 100 * (1.0 - alpha / 2)))\n",
    "            lower_mse.append(np.percentile(boot_samples_mse, 100 * (alpha / 2)))\n",
    "            mean_mse.append(np.percentile(boot_samples_mse, 50))\n",
    "            upper_mse.append(np.percentile(boot_samples_mse, 100 * (1.0 - alpha / 2)))\n",
    "\n",
    "\n",
    "        bias_df = DataFrame(DataFrame(bias_dict[candidate_policy_name]).stack())\\\n",
    "        .reset_index(0).rename(columns={\"level_0\": \"est\", 0: \"bias\"})\n",
    "        bias_df['lower']=lower_bias\n",
    "        bias_df['mean']=mean_bias\n",
    "        bias_df['upper']=upper_bias\n",
    "        bias_df[variable_name] = variable\n",
    "        bias_df_list.append(bias_df)\n",
    "        variance_df = DataFrame(DataFrame(variance_dict[candidate_policy_name]).stack())\\\n",
    "        .reset_index(0).rename(columns={\"level_0\": \"est\", 0: \"variance\"})\n",
    "        variance_df['lower']=lower_variance\n",
    "        variance_df['mean']=mean_variance\n",
    "        variance_df['upper']=upper_variance\n",
    "        variance_df[variable_name] = variable\n",
    "        variance_df_list.append(variance_df)\n",
    "        mse_df = DataFrame(DataFrame(mse_dict[candidate_policy_name]).stack())\\\n",
    "        .reset_index(0).rename(columns={\"level_0\": \"est\", 0: \"mse\"})\n",
    "        mse_df['lower']=lower_mse\n",
    "        mse_df['mean']=mean_mse\n",
    "        mse_df['upper']=upper_mse\n",
    "        mse_df[variable_name] = variable\n",
    "        mse_df_list.append(mse_df)\n",
    "\n",
    "\n",
    "    # aggregate all results \n",
    "    bias_result_df = pd.concat(bias_df_list).reset_index(level=0)\n",
    "    variance_result_df = pd.concat(variance_df_list).reset_index(level=0)\n",
    "    mse_result_df = pd.concat(mse_df_list).reset_index(level=0)\n",
    "\n",
    "    path_ = Path(\"logs\" + f\"/results/df\")\n",
    "    path_.mkdir(exist_ok=True, parents=True)\n",
    "    path_bias = Path(path_ / f\"bias_result_df_{variable_name}.pkl\")\n",
    "    path_variance = Path(path_ / f\"variance_result_df_{variable_name}.pkl\")\n",
    "    path_mse = Path(path_ / f\"mse_result_df_{variable_name}.pkl\")\n",
    "\n",
    "    with open(path_bias, \"wb\") as f:\n",
    "        pickle.dump(bias_result_df, f)\n",
    "    with open(path_variance, \"wb\") as f:\n",
    "        pickle.dump(variance_result_df, f)\n",
    "    with open(path_mse, \"wb\") as f:\n",
    "        pickle.dump(mse_result_df, f)\n",
    "\n",
    "    return bias_result_df, variance_result_df, mse_result_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # path_ = Path(\"logs_tau=0.0\" + f\"/results/df\")\n",
    "# path_ = Path(\"logs_epsilon=0.5\" + f\"/results/df\")\n",
    "\n",
    "# # variable_name='step_per_trajectory'\n",
    "# variable_name='n_trajectories'\n",
    "# # variable_name='n_actions'\n",
    "\n",
    "\n",
    "# path_bias = Path(path_ / f\"bias_result_df_{variable_name}.pkl\")\n",
    "# path_variance = Path(path_ / f\"variance_result_df_{variable_name}.pkl\")\n",
    "# path_mse = Path(path_ / f\"mse_result_df_{variable_name}.pkl\")\n",
    "# with open(path_bias, \"rb\") as f:\n",
    "#     bias_result_df = pickle.load(f)\n",
    "# with open(path_variance, \"rb\") as f:\n",
    "#     variance_result_df = pickle.load(f)\n",
    "# with open(path_mse, \"rb\") as f:\n",
    "#     mse_result_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_estimators = [\"DM\", \"TIS\", \"PDIS\", \"DR\", \"SNTIS\", \"SNPDIS\", \"SNDR\"]\n",
    "state_marginal_estimators = [\"SMIS\", \"SMDR\", \"SMSNIS\", \"SMSNDR\"]\n",
    "state_action_marginal_estimators = [\"SAMIS\", \"SAMDR\", \"SAMSNIS\", \"SAMSNDR\"]\n",
    "drl_estimators = [\"DRL\"]\n",
    "all_estimators = basic_estimators + state_marginal_estimators + state_action_marginal_estimators + drl_estimators\n",
    "\n",
    "basic_estimators_name = [\"dm\", \"tis\", \"pdis\", \"dr\", \"sntis\", \"snpdis\", \"sndr\"]\n",
    "state_marginal_estimators_name = [\"sm_is\", \"sm_dr\", \"sm_snis\", \"sm_sndr\"]\n",
    "state_action_marginal_estimators_name = [\"sam_is\", \"sam_dr\", \"sam_snis\", \"sam_sndr\"]\n",
    "drl_estimators_name = [\"drl\"]\n",
    "all_estimators_name = basic_estimators_name + state_marginal_estimators_name + state_action_marginal_estimators_name + drl_estimators_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_.choice(samples, size=samples.shape[0]) [1.88399474 1.7650226 ]\n",
      "random_.choice(samples, size=samples.shape[0]) [ 0.05086608 -0.15018423]\n",
      "random_.choice(samples, size=samples.shape[0]) [2.45411761 0.9227658 ]\n",
      "random_.choice(samples, size=samples.shape[0]) [1.54985304 1.54985304]\n",
      "random_.choice(samples, size=samples.shape[0]) [1.63223348 1.63223348]\n",
      "random_.choice(samples, size=samples.shape[0]) [1.46040379 1.46040379]\n",
      "random_.choice(samples, size=samples.shape[0]) [1.55756207 1.55756207]\n",
      "random_.choice(samples, size=samples.shape[0]) [1.65855071 1.71768138]\n",
      "random_.choice(samples, size=samples.shape[0]) [0.13337964 0.14421047]\n",
      "random_.choice(samples, size=samples.shape[0]) [-0.29644228 -0.29644228]\n",
      "random_.choice(samples, size=samples.shape[0]) [0.22433437 0.24468132]\n",
      "random_.choice(samples, size=samples.shape[0]) [-0.42146506  0.16130202]\n",
      "random_.choice(samples, size=samples.shape[0]) [0.21206927 0.21206927]\n",
      "random_.choice(samples, size=samples.shape[0]) [ 0.20911453 -0.19460039]\n",
      "random_.choice(samples, size=samples.shape[0]) [0.34775028 0.29763556]\n",
      "random_.choice(samples, size=samples.shape[0]) [0.27241127 0.27241127]\n",
      "random_.choice(samples, size=samples.shape[0]) [-0.19478897  0.21095299]\n"
     ]
    }
   ],
   "source": [
    "bias_result_df, variance_result_df, mse_result_df =main(\n",
    "    variable_name = \"n_trajectories\",\n",
    "    n_random_state = 2,\n",
    "    log_dir=\"../tutorial/logs/\",\n",
    "    behavior_tau = 5.0,\n",
    "    candidate_epsilons = [0.5],\n",
    "    behavior_sigma = 1.0,\n",
    "    candidate_sigmas = [1.0],\n",
    "    action_type = 'discrete',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias_result_df, variance_result_df, mse_result_df =main(\n",
    "#     variable_name = \"n_trajectories\",\n",
    "#     n_random_state = 4,\n",
    "#     log_dir=\"../tutorial/logs_epsilon=0.5/\",\n",
    "#     behavior_tau = 5.0,\n",
    "#     candidate_epsilons = [0.5],\n",
    "#     behavior_sigma = 1.0,\n",
    "#     candidate_sigmas = [1.0],\n",
    "#     action_type = 'discrete',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>est</th>\n",
       "      <th>variance</th>\n",
       "      <th>lower</th>\n",
       "      <th>mean</th>\n",
       "      <th>upper</th>\n",
       "      <th>n_trajectories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tis</td>\n",
       "      <td>1.172519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58626</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  est  variance  lower  mean    upper  n_trajectories\n",
       "2      0  tis  1.172519    0.0   0.0  0.58626             400"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance_result_df[bias_result_df['est']=='tis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>est</th>\n",
       "      <th>variance</th>\n",
       "      <th>lower</th>\n",
       "      <th>mean</th>\n",
       "      <th>upper</th>\n",
       "      <th>n_trajectories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>on_policy</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dm</td>\n",
       "      <td>0.020211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tis</td>\n",
       "      <td>1.172519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586260</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>pdis</td>\n",
       "      <td>0.080699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040350</td>\n",
       "      <td>0.040350</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>dr</td>\n",
       "      <td>0.111598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055799</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>sntis</td>\n",
       "      <td>0.058441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029221</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>snpdis</td>\n",
       "      <td>0.005477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>sndr</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>sm_is</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>sm_dr</td>\n",
       "      <td>0.094287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047143</td>\n",
       "      <td>0.047143</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>sm_snis</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>sm_sndr</td>\n",
       "      <td>0.169809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084904</td>\n",
       "      <td>0.084904</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>sam_is</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>sam_dr</td>\n",
       "      <td>0.081493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040746</td>\n",
       "      <td>0.040746</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>sam_snis</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>sam_sndr</td>\n",
       "      <td>0.117264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058632</td>\n",
       "      <td>0.058632</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>drl</td>\n",
       "      <td>0.082313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041157</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index        est  variance  lower      mean     upper  n_trajectories\n",
       "0       0  on_policy  0.007077    0.0  0.000000  0.003539             400\n",
       "1       0         dm  0.020211    0.0  0.010105  0.010105             400\n",
       "2       0        tis  1.172519    0.0  0.000000  0.586260             400\n",
       "3       0       pdis  0.080699    0.0  0.040350  0.040350             400\n",
       "4       0         dr  0.111598    0.0  0.000000  0.055799             400\n",
       "5       0      sntis  0.058441    0.0  0.000000  0.029221             400\n",
       "6       0     snpdis  0.005477    0.0  0.001369  0.002739             400\n",
       "7       0       sndr  0.001748    0.0  0.000874  0.000874             400\n",
       "8       0      sm_is  0.000059    0.0  0.000000  0.000029             400\n",
       "9       0      sm_dr  0.094287    0.0  0.047143  0.047143             400\n",
       "10      0    sm_snis  0.000207    0.0  0.000000  0.000103             400\n",
       "11      0    sm_sndr  0.169809    0.0  0.084904  0.084904             400\n",
       "12      0     sam_is  0.000829    0.0  0.000000  0.000414             400\n",
       "13      0     sam_dr  0.081493    0.0  0.040746  0.040746             400\n",
       "14      0   sam_snis  0.001256    0.0  0.000314  0.000628             400\n",
       "15      0   sam_sndr  0.117264    0.0  0.058632  0.058632             400\n",
       "16      0        drl  0.082313    0.0  0.000000  0.041157             400"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bias_result_df, variance_result_df, mse_result_df =main(\n",
    "#     variable_name = \"n_trajectories\",\n",
    "#     n_random_state = 2,\n",
    "#     log_dir=\"../tutorial/logs_epsilon=0.5/\",\n",
    "#     behavior_tau = 0.0,\n",
    "#     candidate_epsilons = [0.5],\n",
    "#     behavior_sigma = 1.0,\n",
    "#     candidate_sigmas = [1.0],\n",
    "#     action_type = 'discrete',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTIMATORS=[\"TIS\", \"PDIS\"]\n",
    "# estimators=[\"tis\", \"pdis\"]\n",
    "ESTIMATORS=[\"DM\", \"TIS\"]\n",
    "estimators=[\"dm\", \"tis\"]\n",
    "# ESTIMATORS=basic_estimators\n",
    "# estimators=basic_estimators_name\n",
    "x_scales=[200, 400, 800, 1600, 3200,4800, 6400, 8000]\n",
    "x_label='n_trajectories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (8,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb セル 16\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m visualize(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     bias_result_df,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     variance_result_df,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     mse_result_df,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     ESTIMATORS\u001b[39m=\u001b[39;49mESTIMATORS,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     estimators\u001b[39m=\u001b[39;49mestimators,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     x_scales\u001b[39m=\u001b[39;49mx_scales,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     x_label\u001b[39m=\u001b[39;49mx_label,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# yscale_log=True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# xscale_log=True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb セル 16\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m data \u001b[39m=\u001b[39m result_df[result_df[\u001b[39m'\u001b[39m\u001b[39mest\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39mestimator]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mquery(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmin\u001b[39m(x_scales)\u001b[39m}\u001b[39;00m\u001b[39m<= \u001b[39m\u001b[39m{\u001b[39;00mx_label\u001b[39m}\u001b[39;00m\u001b[39m <= \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmax\u001b[39m(x_scales)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m ax\u001b[39m.\u001b[39;49mplot(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     np\u001b[39m.\u001b[39;49marray([\u001b[39m200\u001b[39;49m, \u001b[39m400\u001b[39;49m, \u001b[39m800\u001b[39;49m, \u001b[39m1600\u001b[39;49m, \u001b[39m3200\u001b[39;49m, \u001b[39m4800\u001b[39;49m, \u001b[39m6400\u001b[39;49m, \u001b[39m8000\u001b[39;49m]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     data[metric],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     color\u001b[39m=\u001b[39;49mcolors[i],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     marker\u001b[39m=\u001b[39;49mmarkers[i],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     label\u001b[39m=\u001b[39;49mESTIMATORS[i],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m ax\u001b[39m.\u001b[39mlegend(ESTIMATORS, loc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mupper right\u001b[39m\u001b[39m\"\u001b[39m, fontsize\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m ax\u001b[39m.\u001b[39mfill_between(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     np\u001b[39m.\u001b[39marray([\u001b[39m200\u001b[39m, \u001b[39m400\u001b[39m, \u001b[39m800\u001b[39m, \u001b[39m1600\u001b[39m, \u001b[39m3200\u001b[39m, \u001b[39m4800\u001b[39m, \u001b[39m6400\u001b[39m, \u001b[39m8000\u001b[39m]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mlower\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ren/dev/scope-rl/tutorial/tutorial_debug.ipynb#X15sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m )\n",
      "File \u001b[0;32m~/negocia_ofrl/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/negocia_ofrl/lib/python3.10/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[1;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[0;32m~/negocia_ofrl/lib/python3.10/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (8,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAKyCAYAAADIG729AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApLUlEQVR4nO3df2zVd7348ddpepqLmtLxoymO0K7y43pNsx/ovAGiMOKGrjFjY8s2b/QGJcOYzMTrvIpZ1FxI7DQ6MkyMwbih8it4QX4FNzcWI5B4r5tu3bIxx4jbgNGGHRoM1Hbt9w9D77dSZk/HC8rp45Hwx/nk8znnfZLX2frs53M+LfT39/cHAAAAcMFVXeoFAAAAQKUS3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkKS63AOef/752L59e7zyyivx5ptvxpe//OW4/vrr3/aY5557LtatWxevvvpqTJw4MW677baYP3/+SNcMAAAAl4Wyz3R3d3dHU1NTfPaznx3W/sePH49vf/vb8YEPfCAeeOCBuPnmm+OHP/xh/OEPfyj3pQEAAOCyUvaZ7muvvTauvfbaYe//6KOPRn19fXz605+OiIipU6fGCy+8ELt27Yprrrmm3JcHAACAy0b6d7pfeumlaGlpGbTt6quvjoMHD2a/NAAAAFxSZZ/pLlepVIrx48cP2jZ+/Pg4ffp0/PWvf42amppzjunp6Ymenp5B24rFYhSLxdS1AgAAwIWUHt0jsXXr1tiyZcvA47lz58YXv/jFS7giAAAAKF96dNfV1cXJkycHbTt58mSMGzduyLPcERGLFy+O1tbWgceFQiEiIt58883o7e3NWyxcIoVCISZNmhSdnZ3R399/qZcDKcw5lc6MMxaYcypddXV1XHHFFRf2OS/osw1hxowZ8fTTTw/a9swzz8TMmTPPe8z5LiXv7e0957JzqARnf7HU09Pjf2BULHNOpTPjjAXmHMpX9o3Uzpw5E4cPH47Dhw9HxN/+JNjhw4ejs7MzIiLWr18fa9asGdj/xhtvjOPHj8fPfvazeP311+NXv/pVHDhwIG6++eYL8w4AAABglCr7TPfLL78c3/rWtwYer1u3LiIiPvrRj8YXvvCFePPNNwcCPCKivr4+vvrVr8YjjzwSu3fvjokTJ8by5cv9uTAAAAAqXqH/MroupKOjw+XlVKRCoRBTpkyJo0ePulSLimXOqXRmnLHAnFPpisViTJ48+YI+Z/rf6QYAAICxSnQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJCkeiQH7dmzJ3bs2BGlUikaGxtj6dKlMX369PPuv2vXrnj00Uejs7Mzamtr48Mf/nDcfffdUVNTM+KFAwAAwGhX9pnu/fv3x7p162LJkiXR1tYWjY2NsWrVqjh58uSQ+//2t7+N9evXx+233x7f//73Y/ny5XHgwIHYsGHDO148AAAAjGZlR/fOnTtj4cKFsWDBgpg6dWosW7YsampqYu/evUPu/+KLL8asWbNi3rx5UV9fH1dffXXMnTs3/vSnP73jxQMAAMBoVlZ09/b2xqFDh6KlpeX/nqCqKlpaWuLgwYNDHjNr1qw4dOjQQGS/8cYb8fTTT8e11177DpYNAAAAo19Z3+nu6uqKvr6+qKurG7S9rq4ujhw5MuQx8+bNi66urrj//vsjIuKtt96Kj33sY3Hrrbee93V6enqip6dn4HGhUIhx48ZFoVCIQqFQzpLhsnB2rs03lcycU+nMOGOBOafSZcz2iG6kVo7nnnsutm7dGp/73OdixowZcezYsfjJT34SW7ZsiSVLlgx5zNatW2PLli0Dj6+66qpoa2uLSZMmZS8XLqmGhoZLvQRIZ86pdGacscCcw/CVFd21tbVRVVUVpVJp0PZSqXTO2e+zNm3aFB/5yEdi4cKFERExbdq0OHPmTPzoRz+KW2+9Naqqzr3CffHixdHa2jrw+OxvGzo7OwedAYdKUSgUoqGhIY4dOxb9/f2XejmQwpxT6cw4Y4E5p9IVi8ULfrK3rOiurq6O5ubmaG9vj+uvvz4iIvr6+qK9vT0WLVo05DHd3d3nnKIfKrT/f8ViMYrF4jnb+/v7fbipaGacscCcU+nMOGOBOadSZcx12ZeXt7a2xg9+8INobm6O6dOnx+7du6O7uzvmz58fERFr1qyJCRMmxN133x0REbNnz45du3bFVVddNXB5+aZNm2L27Nn/ML4BAADgclZ2dM+ZMye6urpi8+bNUSqVoqmpKVasWDFweXlnZ+egM9u33XZbFAqF2LhxY5w4cSJqa2tj9uzZcdddd12wNwEAAACjUaH/MroupKOjw3e6qUiFQiGmTJkSR48edakWFcucU+nMOGOBOafSFYvFmDx58gV9Ttd3AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAkuqRHLRnz57YsWNHlEqlaGxsjKVLl8b06dPPu/9f/vKX2LBhQ/zud7+LU6dOxeTJk+Mzn/lMXHfddSNeOAAAAIx2ZUf3/v37Y926dbFs2bKYMWNG7Nq1K1atWhUPPvhgjB8//pz9e3t7Y+XKlVFbWxtf+tKXYsKECdHZ2Rnvete7LsgbAAAAgNGq7OjeuXNnLFy4MBYsWBAREcuWLYunnnoq9u7dG7fccss5+z/xxBNx6tSp+K//+q+orv7by9XX17+zVQMAAMBloKzo7u3tjUOHDg2K66qqqmhpaYmDBw8Oeczvf//7mDFjRvz4xz+O//3f/43a2tqYO3du3HLLLVFV5SvlAAAAVK6yorurqyv6+vqirq5u0Pa6uro4cuTIkMe88cYb0dHREfPmzYuvfe1rcezYsVi7dm289dZbcfvttw95TE9PT/T09Aw8LhQKMW7cuCgUClEoFMpZMlwWzs61+aaSmXMqnRlnLDDnVLqM2R7RjdTK0d/fH7W1tXHPPfdEVVVVNDc3x4kTJ2L79u3nje6tW7fGli1bBh5fddVV0dbWFpMmTcpeLlxSDQ0Nl3oJkM6cU+nMOGOBOYfhKyu6a2tro6qqKkql0qDtpVLpnLPfZ9XV1UV1dfWgS8mvvPLKKJVK0dvbO/A97//f4sWLo7W1deDx2d82dHZ2DjoDDpWiUChEQ0NDHDt2LPr7+y/1ciCFOafSmXHGAnNOpSsWixf8ZG9Z0V1dXR3Nzc3R3t4e119/fURE9PX1RXt7eyxatGjIY2bNmhX79u2Lvr6+gfA+evRoXHHFFUMGd8Tf3mixWDxne39/vw83Fc2MMxaYcyqdGWcsMOdUqoy5LvtOZq2trfH444/Hk08+Ga+99lqsXbs2uru7Y/78+RERsWbNmli/fv3A/jfeeGOcOnUqHn744Thy5Eg89dRTsXXr1rjpppsu2JsAAACA0ajs73TPmTMnurq6YvPmzVEqlaKpqSlWrFgxcHl5Z2fnoC+fT5o0Kb7+9a/HI488Evfdd19MmDAhPv7xjw/558UAAACgkhT6L6PrQjo6Onynm4pUKBRiypQpcfToUZdqUbHMOZXOjDMWmHMqXbFYjMmTJ1/Q5/SHsgEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIEn1SA7as2dP7NixI0qlUjQ2NsbSpUtj+vTp//C4ffv2xerVq+ODH/xgfOUrXxnJSwMAAMBlo+wz3fv3749169bFkiVLoq2tLRobG2PVqlVx8uTJtz3u+PHj8dOf/jTe//73j3ixAAAAcDkpO7p37twZCxcujAULFsTUqVNj2bJlUVNTE3v37j3vMX19ffHQQw/FHXfcEfX19e9owQAAAHC5KCu6e3t749ChQ9HS0vJ/T1BVFS0tLXHw4MHzHrdly5aora2NG264YeQrBQAAgMtMWd/p7urqir6+vqirqxu0va6uLo4cOTLkMS+88EI88cQT8cADDwz7dXp6eqKnp2fgcaFQiHHjxkWhUIhCoVDOkuGycHauzTeVzJxT6cw4Y4E5p9JlzPaIbqQ2XKdPn46HHnoo7rnnnqitrR32cVu3bo0tW7YMPL7qqquira0tJk2alLFMGDUaGhou9RIgnTmn0plxxgJzDsNXVnTX1tZGVVVVlEqlQdtLpdI5Z78jIt54443o6OiItra2gW39/f0REXHnnXfGgw8+OOQHdvHixdHa2jrw+OxvGzo7OwedAYdKUSgUoqGhIY4dOzbwGYFKY86pdGacscCcU+mKxeIFP9lbVnRXV1dHc3NztLe3x/XXXx8Rf7tJWnt7eyxatOic/d/73vfGd7/73UHbNm7cGGfOnIl///d/P++bKRaLUSwWz9ne39/vw01FM+OMBeacSmfGGQvMOZUqY67Lvry8tbU1fvCDH0Rzc3NMnz49du/eHd3d3TF//vyIiFizZk1MmDAh7r777qipqYlp06YNOv7d7353RMQ52wEAAKDSlB3dc+bMia6urti8eXOUSqVoamqKFStWDFxe3tnZ6cYKAAAAEBGF/svoupCOjg7f6aYiFQqFmDJlShw9etSlWlQsc06lM+OMBeacSlcsFmPy5MkX9DnL+jvdAAAAwPCJbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJKIbAAAAkohuAAAASFI9koP27NkTO3bsiFKpFI2NjbF06dKYPn36kPv++te/jt/85jfx6quvRkREc3Nz3HXXXefdHwAAACpF2We69+/fH+vWrYslS5ZEW1tbNDY2xqpVq+LkyZND7v/888/H3Llz4xvf+EasXLkyJk6cGCtXrowTJ06848UDAADAaFZ2dO/cuTMWLlwYCxYsiKlTp8ayZcuipqYm9u7dO+T+9957b9x0003R1NQUV155ZSxfvjz6+/vj2WeffceLBwAAgNGsrMvLe3t749ChQ3HLLbcMbKuqqoqWlpY4ePDgsJ6ju7s7ent74z3vec959+np6Ymenp6Bx4VCIcaNGxeFQiEKhUI5S4bLwtm5Nt9UMnNOpTPjjAXmnEqXMdtlRXdXV1f09fVFXV3doO11dXVx5MiRYT3Hz3/+85gwYUK0tLScd5+tW7fGli1bBh5fddVV0dbWFpMmTSpnuXDZaWhouNRLgHTmnEpnxhkLzDkM34hupDZS27Zti3379sU3v/nNqKmpOe9+ixcvjtbW1oHHZ3/b0NnZOegMOFSKQqEQDQ0NcezYsejv77/Uy4EU5pxKZ8YZC8w5la5YLF7wk71lRXdtbW1UVVVFqVQatL1UKp1z9vvvbd++PbZt2xb3339/NDY2vu2+xWIxisXiOdv7+/t9uKloZpyxwJxT6cw4Y4E5p1JlzHVZN1Krrq6O5ubmaG9vH9jW19cX7e3tMXPmzPMe98tf/jJ+8YtfxIoVK+J973vfyFcLAAAAl5Gy717e2toajz/+eDz55JPx2muvxdq1a6O7uzvmz58fERFr1qyJ9evXD+y/bdu22LRpU3z+85+P+vr6KJVKUSqV4syZMxfsTQAAAMBoVPZ3uufMmRNdXV2xefPmKJVK0dTUFCtWrBi4vLyzs3PQHd8ee+yx6O3tje9973uDnmfJkiVxxx13vLPVAwAAwChW6L+MvozR0dHhRmpUpEKhEFOmTImjR4/6fhQVy5xT6cw4Y4E5p9IVi8WYPHnyBX3Osi8vBwAAAIZHdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkER0AwAAQBLRDQAAAElENwAAACQR3QAAAJBEdAMAAEAS0Q0AAABJRDcAAAAkEd0AAACQRHQDAABAEtENAAAASUQ3AAAAJBHdAAAAkKR6JAft2bMnduzYEaVSKRobG2Pp0qUxffr08+5/4MCB2LRpU3R0dERDQ0N86lOfiuuuu27EiwYAAIDLQdlnuvfv3x/r1q2LJUuWRFtbWzQ2NsaqVavi5MmTQ+7/4osvxurVq+OGG26Itra2+NCHPhTf+c534s9//vM7XjwAAACMZmVH986dO2PhwoWxYMGCmDp1aixbtixqampi7969Q+6/e/fuuOaaa+KTn/xkTJ06Ne68885obm6OPXv2vOPFAwAAwGhW1uXlvb29cejQobjlllsGtlVVVUVLS0scPHhwyGMOHjwYra2tg7ZdffXV8T//8z/nfZ2enp7o6ekZeFwoFGLcuHFRXT2iq+Fh1CsUChERUSwWo7+//xKvBnKYcyqdGWcsMOdUuozmLOsZu7q6oq+vL+rq6gZtr6uriyNHjgx5TKlUivHjxw/aNn78+CiVSud9na1bt8aWLVsGHs+dOze++MUvxhVXXFHOcuGyM2nSpEu9BEhnzql0ZpyxwJxT6Xp6eqJYLF6Q5xqVdy9fvHhxPPzwwwP//u3f/i1Wr14dp0+fvtRLgxSnT5+O//zP/zTjVDRzTqUz44wF5pxKd/r06Vi9evWgK6/fqbKiu7a2Nqqqqs45S10qlc45+31WXV3dOTdZO3ny5Hn3j/jb5Srvete7Bv6NGzcu9u3b5xIWKlZ/f3+88sorZpyKZs6pdGacscCcU+n6+/tj3759F/Q5y4ru6urqaG5ujvb29oFtfX190d7eHjNnzhzymJkzZ8azzz47aNszzzwTM2bMGMFyAQAA4PJR9uXlra2t8fjjj8eTTz4Zr732Wqxduza6u7tj/vz5ERGxZs2aWL9+/cD+n/jEJ+KPf/xj7NixI15//fXYvHlzvPzyy7Fo0aIL9iYAAABgNCr71mxz5syJrq6u2Lx5c5RKpWhqaooVK1YMXC7e2dk5cFfDiIhZs2bFvffeGxs3bowNGzbElClT4r777otp06YN+zWLxWIsWbLkgn2RHUYbM85YYM6pdGacscCcU+kyZrzQ7wsZAAAAkGJU3r0cAAAAKoHoBgAAgCSiGwAAAJKIbgAAAEhS9t3Ls+zZsyd27NgRpVIpGhsbY+nSpTF9+vTz7n/gwIHYtGlTdHR0RENDQ3zqU5+K66677iKuGMpTzoz/+te/jt/85jfx6quvRkREc3Nz3HXXXW/7mYDRoNz/lp+1b9++WL16dXzwgx+Mr3zlKxdhpTAy5c74X/7yl9iwYUP87ne/i1OnTsXkyZPjM5/5jJ9ZGLXKnfFdu3bFo48+Gp2dnVFbWxsf/vCH4+67746ampqLuGoYvueffz62b98er7zySrz55pvx5S9/Oa6//vq3Pea5556LdevWxauvvhoTJ06M2267beBPZg/HqDjTvX///li3bl0sWbIk2traorGxMVatWhUnT54ccv8XX3wxVq9eHTfccEO0tbXFhz70ofjOd74Tf/7zny/yymF4yp3x559/PubOnRvf+MY3YuXKlTFx4sRYuXJlnDhx4iKvHIav3Dk/6/jx4/HTn/403v/+91+klcLIlDvjvb29sXLlyujo6IgvfelL8eCDD8Y999wTEyZMuMgrh+Epd8Z/+9vfxvr16+P222+P73//+7F8+fI4cOBAbNiw4SKvHIavu7s7mpqa4rOf/eyw9j9+/Hh8+9vfjg984APxwAMPxM033xw//OEP4w9/+MOwX3NURPfOnTtj4cKFsWDBgpg6dWosW7YsampqYu/evUPuv3v37rjmmmvik5/8ZEydOjXuvPPOaG5ujj179lzklcPwlDvj9957b9x0003R1NQUV155ZSxfvjz6+/vj2Wefvcgrh+Erd84jIvr6+uKhhx6KO+64I+rr6y/iaqF85c74E088EadOnYr77rsv/vmf/znq6+vjX/7lX6KpqeniLhyGqdwZf/HFF2PWrFkxb968qK+vj6uvvjrmzp0bf/rTny7yymH4rr322rjzzjv/4dntsx599NGor6+PT3/60zF16tRYtGhR/Ou//mvs2rVr2K95yaO7t7c3Dh06FC0tLQPbqqqqoqWlJQ4ePDjkMQcPHhy0f0TE1VdfHS+99FLqWmEkRjLjf6+7uzt6e3vjPe95T9Yy4R0Z6Zxv2bIlamtr44YbbrgYy4QRG8mM//73v48ZM2bEj3/841i2bFn8x3/8R/z3f/939PX1Xaxlw7CNZMZnzZoVhw4dGojsN954I55++um49tprL8qa4WJ46aWXhmzP4f4cHzEKvtPd1dUVfX19UVdXN2h7XV1dHDlyZMhjSqVSjB8/ftC28ePHR6lUSloljNxIZvzv/fznP48JEyac84GH0WIkc/7CCy/EE088EQ888MBFWCG8MyOZ8TfeeCM6Ojpi3rx58bWvfS2OHTsWa9eujbfeeituv/32i7BqGL6RzPi8efOiq6sr7r///oiIeOutt+JjH/tY3HrrrdnLhYvmfO15+vTp+Otf/zqs+xdc8ugG3t62bdti37598c1vftNNSagYp0+fjoceeijuueeeqK2tvdTLgRT9/f1RW1sb99xzT1RVVUVzc3OcOHEitm/fLrqpCM8991xs3bo1Pve5z8WMGTPi2LFj8ZOf/CS2bNkSS5YsudTLg1Hjkkd3bW1tVFVVnXOWulQqnfObtrPq6urOuaHDyZMnz7s/XEojmfGztm/fHtu2bYv7778/Ghsb8xYJ71C5c372DGBbW9vAtv7+/oiIuPPOO+PBBx+MhoaGzCVDWUb680p1dXVUVf3ft/muvPLKKJVK0dvbG9XVl/zHMBgwkhnftGlTfOQjH4mFCxdGRMS0adPizJkz8aMf/ShuvfXWQbMPl6vztee4ceOGfULskn8Sqquro7m5Odrb2we29fX1RXt7e8ycOXPIY2bOnHnODaWeeeaZmDFjRupaYSRGMuMREb/85S/jF7/4RaxYsSLe9773XYylwoiVO+fvfe9747vf/W488MADA/9mz549cGfQSZMmXczlwz80kv+Wz5o1K44dOzboO9xHjx6NK664QnAz6oxkxru7u6NQKAzaJrSpNDNmzBiyPd/u5/i/Nyo+Fa2trfH444/Hk08+Ga+99lqsXbs2uru7B/722Zo1a2L9+vUD+3/iE5+IP/7xj7Fjx454/fXXY/PmzfHyyy/HokWLLtE7gLdX7oxv27YtNm3aFJ///Oejvr4+SqVSlEqlOHPmzCV6B/CPlTPnNTU1MW3atEH/3v3ud8c//dM/xbRp0wQJo1K5/y2/8cYb49SpU/Hwww/HkSNH4qmnnoqtW7fGTTfddIneAby9cmd89uzZ8dhjj8W+ffvi+PHj8cwzz8SmTZti9uzZ4ptR68yZM3H48OE4fPhwRPztT4IdPnw4Ojs7IyJi/fr1sWbNmoH9b7zxxjh+/Hj87Gc/i9dffz1+9atfxYEDB+Lmm28e9muOip9q5syZE11dXbF58+YolUrR1NQUK1asGLiUpbOzc9Bv0WbNmhX33ntvbNy4MTZs2BBTpkyJ++67L6ZNm3aJ3gG8vXJn/LHHHove3t743ve+N+h5lixZEnfcccfFXDoMW7lzDpebcmd80qRJ8fWvfz0eeeSRuO+++2LChAnx8Y9/PG655ZZL8wbgHyh3xm+77bYoFAqxcePGOHHiRNTW1sbs2bPjrrvuukTvAP6xl19+Ob71rW8NPF63bl1ERHz0ox+NL3zhC/Hmm28OBHhERH19fXz1q1+NRx55JHbv3h0TJ06M5cuXxzXXXDPs1yz0n/0SHQAAAHBBue4DAAAAkohuAAAASCK6AQAAIInoBgAAgCSiGwAAAJKIbgAAAEgiugEAACCJ6AYAAIAkohsAAACSiG4AAABIIroBAAAgiegGAACAJP8PGxd7jnPe5osAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(\n",
    "    bias_result_df,\n",
    "    variance_result_df,\n",
    "    mse_result_df,\n",
    "    ESTIMATORS=ESTIMATORS,\n",
    "    estimators=estimators,\n",
    "    x_scales=x_scales,\n",
    "    x_label=x_label,\n",
    "    # yscale_log=True,\n",
    "    # xscale_log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "negocia_ofrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
