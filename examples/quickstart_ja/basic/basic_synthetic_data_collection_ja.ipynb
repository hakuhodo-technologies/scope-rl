{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart: 簡単な設定でのシミュレーションと人工データセット (データ収集)\n",
    "このノートブックは簡単なシミュレーション環境から集められたログデータの可視化の例を紹介します．\n",
    "\n",
    "特に、以下の3つの順番で解説していきます: \n",
    "\n",
    "0. (シミュレーション環境の設定とオンライン強化学習)\n",
    "1. 離散行動空間における事例\n",
    "2. 連続行動空間における事例\n",
    "3. 複数のデータ収集方策方策やランダムシードによるログデータの収集\n",
    "\n",
    "\n",
    "このライブラリは，オンラインとオフラインの方策学習およびモデルベースのオフ方策評価の一部で [d3rlpy](https://github.com/takuseno/d3rlpy)のアルゴリズムを利用しています．\n",
    "また、実装のワークフローは[Open Bandit Pipeline](https://github.com/st-tech/zr-obp)を参考にしています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCOPE-RL モジュールのインポート\n",
    "import scope_rl\n",
    "from basicgym import BasicEnv\n",
    "from scope_rl.dataset import SyntheticDataset\n",
    "from scope_rl.policy import OnlineHead\n",
    "from scope_rl.ope.online import (\n",
    "    calc_on_policy_policy_value,\n",
    "    visualize_on_policy_policy_value,\n",
    ")\n",
    "\n",
    "# d3rlpy アルゴリズムのインポート\n",
    "from d3rlpy.algos import DiscreteRandomPolicyConfig\n",
    "from d3rlpy.algos import RandomPolicyConfig as ContinuousRandomPolicyConfig\n",
    "\n",
    "# その他のライブラリのインポート\n",
    "import gym\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Union, Optional\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2\n"
     ]
    }
   ],
   "source": [
    "# バージョン\n",
    "print(scope_rl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random stateの設定\n",
    "random_state = 12345\n",
    "random_ = check_random_state(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. (シミュレーション環境の設定とオンライン強化学習)\n",
    "まず初めに，今回用いる簡単な環境設定について紹介します．\n",
    "\n",
    "#### 強化学習での環境のセットアップ\n",
    "今回は簡単なシミュレーション環境上で，方策の獲得する累積報酬を最大化する問題を考えます．\n",
    "\n",
    "この強化学習の問題を(部分観測)マルコフ決定過程((PO)MDP)として定式化します．\n",
    "- `状態`: 状態観測（POMDPの場合は観測ノイズが発生）．\n",
    "- `行動`: 強化学習エージェント (方策) により選択された行動．\n",
    "- `報酬`: 状態と行動に応じて観測される報酬．\n",
    "\n",
    "より詳細に環境の引数を確認したい場合は，次のノートブックを参照してください．[examples/quickstart/basic/basic_synthetic_customize_env.ipynb](https://github.com/hakuhodo-technologies/scope-rl/blob/main/examples/quickstart/basic/basic_synthetic_customize_env.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境のセットアップ\n",
    "env = BasicEnv(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムに行動を選択するエージェントを定義\n",
    "agent = OnlineHead(\n",
    "    ContinuousRandomPolicyConfig().create(device=device),\n",
    "    name=\"random\",\n",
    ")\n",
    "agent.build_with_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境とエージェントの相互作用\n",
    "# 6行で強化学習の相互作用を記述できる\n",
    "for episode in range(10):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.predict_online(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "[ 0.37801347 -0.60047514 -0.16326933  0.57911164 -0.36675368]\n"
     ]
    }
   ],
   "source": [
    "# 状態\n",
    "print(obs.shape)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ランダムエージェントでの報酬の推移を可視化\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "reward_list = []\n",
    "\n",
    "while not done:\n",
    "    action = agent.sample_action_online(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    reward_list.append(reward)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(reward_list[:-1], label='reward', color='tab:orange')\n",
    "ax1.set_xlabel('timestep')\n",
    "ax1.set_ylabel('reward')\n",
    "ax1.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 離散行動空間\n",
    "ま図は行動空間が離散の場合にデータ収集方策からどのようにデータを収集するかを紹介します．\n",
    "\n",
    "ここでは2つの手順を必要とします．\n",
    "1. ベースとなる決定的 (非確率的) な方策を学習する．\n",
    "2. 決定的な方策を用い確率的な方策を定義する．\n",
    "\n",
    "決定的な方策を学習する際は[d3rlpy](https://github.com/takuseno/d3rlpy)を利用します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 離散行動空間に対する標準的な環境\n",
    "env = gym.make(\"BasicEnv-discrete-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成のためのベースとなる決定的方策の学習\n",
    "from d3rlpy.algos import DoubleDQNConfig\n",
    "from d3rlpy.models.encoders import VectorEncoderFactory\n",
    "from d3rlpy.models.q_functions import MeanQFunctionFactory\n",
    "from d3rlpy.dataset import create_fifo_replay_buffer\n",
    "from d3rlpy.algos import LinearDecayEpsilonGreedy\n",
    "\n",
    "# モデル\n",
    "ddqn = DoubleDQNConfig(\n",
    "    encoder_factory=VectorEncoderFactory(hidden_units=[30, 30]),\n",
    "    q_func_factory=MeanQFunctionFactory(),\n",
    "    target_update_interval=100,\n",
    ").create(device=device)\n",
    "\n",
    "# 再生バッファ\n",
    "buffer = create_fifo_replay_buffer(\n",
    "    limit=10000,\n",
    "    env=env,\n",
    ")\n",
    "\n",
    "# 探索\n",
    "explorer = LinearDecayEpsilonGreedy(\n",
    "    start_epsilon=1.0,\n",
    "    end_epsilon=0.1,\n",
    "    duration=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の開始\n",
    "# 事前学習したモデルを利用する場合はスキップ\n",
    "ddqn.fit_online(\n",
    "    env,\n",
    "    buffer,\n",
    "    explorer=explorer,\n",
    "    eval_env=env,\n",
    "    n_steps=100000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    update_start_step=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "ddqn.save_model(\"d3rlpy_logs/ddqn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-22 15:27:33 [warning  ] Parameters will be reinitialized.\n"
     ]
    }
   ],
   "source": [
    "# モデルのリロード\n",
    "ddqn.build_with_env(env)\n",
    "ddqn.load_model(\"d3rlpy_logs/ddqn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Epsilon-Greedy 方策\n",
    "\n",
    "ここでは学習した決定的な方策から確率的方策を定義します．\n",
    "\n",
    "今回用いるepsilon-greedy方策では，$1 - \\epsilon$の確率で貪欲に行動を選択し，$\\epsilon$の確率でランダムな行動を選択します．\n",
    "\n",
    "$$\\pi(a | s) := (1 - \\epsilon) * \\pi_{\\mathrm{det}}(a | s) + \\epsilon / |\\mathcal{A}|,$$\n",
    "\n",
    "ここで$a \\in \\mathcal{A}$ は行動，$s \\in \\mathcal{S}$は状態，$\\pi$ は決定的なベース方策$\\pi_{\\mathrm{det}}$を用いて定義された確率的方策です．\n",
    "\n",
    "このepsilon-greedy方策をデータ収集方策として人工データを生成しますが、その際に用いる`SyntheticDataset` は以下の引数を持っています:\n",
    "- `env`: 強化学習の（シミュレーション）環境．\n",
    "- `max_episode_steps`: 一つのエピソードにおける連続意思決定の数（上限）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddqn方策を確率的なデータ収集方策に変えます\n",
    "from scope_rl.policy import EpsilonGreedyHead\n",
    "\n",
    "behavior_policy = EpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.3,  # ランダムな行動をとる確率\n",
    "    name=\"ddqn_epsilon_0.3\",\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成\n",
    "dataset = SyntheticDataset(\n",
    "    env=env,\n",
    "    max_episode_steps=env.step_per_episode,\n",
    ")\n",
    "logged_dataset = dataset.obtain_episodes(\n",
    "    behavior_policies=behavior_policy,\n",
    "    n_trajectories=10000, \n",
    "    obtain_info=False,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 100000,\n",
       " 'n_trajectories': 10000,\n",
       " 'step_per_trajectory': 10,\n",
       " 'action_type': 'discrete',\n",
       " 'n_actions': 10,\n",
       " 'action_dim': None,\n",
       " 'action_meaning': None,\n",
       " 'action_keys': None,\n",
       " 'state_dim': 5,\n",
       " 'state_keys': None,\n",
       " 'state': array([[ 0.46692103, -0.60091272,  0.12748286,  0.10612129,  0.62719618],\n",
       "        [ 0.00305434,  0.25886564,  0.94683458, -0.18441597, -0.04974207],\n",
       "        [ 0.09209668,  0.18060315, -0.96557628, -0.16297735,  0.00123719],\n",
       "        ...,\n",
       "        [-0.32659665, -0.4457801 ,  0.12418311, -0.55321285,  0.61085909],\n",
       "        [ 0.91297429, -0.08570925,  0.24184222, -0.15626001,  0.27609242],\n",
       "        [-0.38500003,  0.06259195,  0.51752316, -0.76154405,  0.00881301]]),\n",
       " 'action': array([6, 1, 6, ..., 8, 6, 5]),\n",
       " 'reward': array([ 0.85571015, -0.27916946,  0.63759116, ...,  0.03190668,\n",
       "         0.79813161,  0.60196688]),\n",
       " 'done': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'terminal': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'info': {},\n",
       " 'pscore': array([0.73, 0.03, 0.73, ..., 0.03, 0.73, 0.03]),\n",
       " 'behavior_policy': 'ddqn_epsilon_0.3',\n",
       " 'dataset_id': 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. ソフトマックス方策\n",
    "次に，epsilon-greedyの代わりに`SoftmaxHead`を用いて確率的なデータ収集方策を定義します．\n",
    "\n",
    "ソフトマックス方策は，状態と行動のペア$(s, a)$が与えられた時に価値を推定するQ関数$Q(s, a)$を用い、以下のように確率的に行動を選択します．\n",
    "\n",
    "$$\\pi(a \\mid s) = \\frac{\\exp(Q(s, a) / \\tau)}{\\sum_{a' \\in A} \\exp(Q(s, a') / \\tau)},$$\n",
    "\n",
    "$\\tau$ は方策のエントロピーを調整する温度パラメータです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddqn方策を確率的なデータ収集方策に変えます\n",
    "\n",
    "from scope_rl.policy import SoftmaxHead\n",
    "\n",
    "behavior_policy = SoftmaxHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    tau=1.0,  # 温度パラメータ\n",
    "    name=\"ddqn_softmax_tau_1.0\",\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成\n",
    "dataset = SyntheticDataset(\n",
    "    env=env,\n",
    "    max_episode_steps=env.step_per_episode,\n",
    ")\n",
    "logged_dataset = dataset.obtain_episodes(\n",
    "    behavior_policies=behavior_policy, \n",
    "    n_trajectories=10000, \n",
    "    obtain_info=False,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 100000,\n",
       " 'n_trajectories': 10000,\n",
       " 'step_per_trajectory': 10,\n",
       " 'action_type': 'discrete',\n",
       " 'n_actions': 10,\n",
       " 'action_dim': None,\n",
       " 'action_meaning': None,\n",
       " 'action_keys': None,\n",
       " 'state_dim': 5,\n",
       " 'state_keys': None,\n",
       " 'state': array([[ 0.46692103, -0.60091272,  0.12748286,  0.10612129,  0.62719618],\n",
       "        [ 0.64485759,  0.51071168, -0.52750824,  0.03342947, -0.20964208],\n",
       "        [ 0.06101586, -0.03246848, -0.82748705, -0.37659153, -0.41069071],\n",
       "        ...,\n",
       "        [ 0.16542329,  0.19496503, -0.86782052, -0.01134997, -0.42589025],\n",
       "        [-0.3159583 , -0.38225619, -0.03900763, -0.55802578, -0.66418085],\n",
       "        [-0.18653574, -0.51963184,  0.68105195, -0.21024438,  0.4326115 ]]),\n",
       " 'action': array([2, 2, 9, ..., 6, 5, 7]),\n",
       " 'reward': array([0.39970333, 0.17633499, 0.35529554, ..., 0.5291534 , 0.43462625,\n",
       "        0.37790305]),\n",
       " 'done': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'terminal': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'info': {},\n",
       " 'pscore': array([0.13459426, 0.05894504, 0.06381392, ..., 0.37515965, 0.03496838,\n",
       "        0.04411056]),\n",
       " 'behavior_policy': 'ddqn_softmax_tau_1.0',\n",
       " 'dataset_id': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "離散行動空間でのオフライン強化学習やオフ方策評価 (OPE) に関しては[examples/quickstart/basic/basic_synthetic_discrete_basic.ipynb](https://github.com/hakuhodo-technologies/scope-rl/blob/main/examples/quickstart/basic/basic_synthetic_discrete_basic.ipynb)を参照してください.\n",
    "\n",
    "オフ方策評価 (OPE) や オフ方策選択 (OPS) に関する発展的なトピックは[examples/quickstart/basic/basic_synthetic_discrete_advanced.ipynb](https://github.com/hakuhodo-technologies/scope-rl/blob/main/examples/quickstart/basic/basic_synthetic_discrete_advanced.ipynb)を参照してください."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 連続行動空間\n",
    "まずは離散行動の場合と同様に，ベースとなる決定的な方策を学習します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連続行動空間に対する標準的な環境\n",
    "env = gym.make(\"BasicEnv-continuous-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成のベースとなる決定的方策の学習\n",
    "from d3rlpy.algos import SACConfig\n",
    "from d3rlpy.models.encoders import VectorEncoderFactory\n",
    "from d3rlpy.models.q_functions import MeanQFunctionFactory\n",
    "from d3rlpy.dataset import create_fifo_replay_buffer\n",
    "\n",
    "# モデル\n",
    "sac = SACConfig(\n",
    "    actor_encoder_factory=VectorEncoderFactory(hidden_units=[30, 30]),\n",
    "    critic_encoder_factory=VectorEncoderFactory(hidden_units=[30, 30]),\n",
    "    q_func_factory=MeanQFunctionFactory(),\n",
    "    action_scaler=MinMaxActionScaler(\n",
    "        minimum=env.action_space.low,   \n",
    "        maximum=env.action_space.high,  \n",
    "    ),\n",
    ").create(device=device)\n",
    "\n",
    "# 再生バッファ\n",
    "buffer = create_fifo_replay_buffer(\n",
    "    limit=10000,\n",
    "    env=env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の開始\n",
    "# 事前学習したモデルを利用する場合はスキップ\n",
    "sac.fit_online(\n",
    "    env,\n",
    "    buffer,\n",
    "    eval_env=env,\n",
    "    n_steps=100000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    update_start_step=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "sac.save_model(\"d3rlpy_logs/sac.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-22 15:41:41 [warning  ] Parameters will be reinitialized.\n"
     ]
    }
   ],
   "source": [
    "# モデルのリロード\n",
    "sac.build_with_env(env)\n",
    "sac.load_model(\"d3rlpy_logs/sac.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. ガウス方策\n",
    "\n",
    "ここでは，学習した決定的方策にノイズを加えることで確率的方策を定義します． \n",
    "\n",
    "今回は，`BasicEnv`の有界な行動空間に対応するために，`TruncatedGaussianHead`を利用します．\n",
    "この方策は決定的方策$\\pi(s)$の選ぶ行動に応じて, 切断ガウス分布から行動をサンプリングします．\n",
    "$$a \\sim Truncnorm(\\pi(s), \\sigma),$$\n",
    "\n",
    "ここで$\\sigma$ノイズの大きさを表しています．\n",
    "\n",
    "行動空間が有界でない時は, `GaussianHead`を利用できます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scope_rl.policy import TruncatedGaussianHead\n",
    "\n",
    "behavior_policy = TruncatedGaussianHead(\n",
    "    sac, \n",
    "    minimum=env.action_space.low,  # 行動空間の下限\n",
    "    maximum=env.action_space.high,  # 行動空間の上限\n",
    "    sigma=np.array([1.0]),  # ガウシアン分布のノイズスケール\n",
    "    name=\"sac_sigma_1.0\",\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ収集\n",
    "dataset = SyntheticDataset(\n",
    "    env=env,\n",
    "    max_episode_steps=env.step_per_episode,\n",
    ")\n",
    "logged_dataset = dataset.obtain_episodes(\n",
    "    behavior_policies=behavior_policy,\n",
    "    n_trajectories=10000, \n",
    "    obtain_info=False,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 100000,\n",
       " 'n_trajectories': 10000,\n",
       " 'step_per_trajectory': 10,\n",
       " 'action_type': 'continuous',\n",
       " 'n_actions': None,\n",
       " 'action_dim': 3,\n",
       " 'action_meaning': None,\n",
       " 'action_keys': None,\n",
       " 'state_dim': 5,\n",
       " 'state_keys': None,\n",
       " 'state': array([[ 0.46692103, -0.60091272,  0.12748286,  0.10612129,  0.62719618],\n",
       "        [ 0.07780383, -0.17498141,  0.97063136,  0.07659025,  0.12384171],\n",
       "        [-0.27403345,  0.53195699,  0.48746454,  0.53854036,  0.3380533 ],\n",
       "        ...,\n",
       "        [-0.13130183, -0.01022507, -0.93221219, -0.09531446, -0.32334327],\n",
       "        [ 0.03276998,  0.3246122 , -0.57501869,  0.21644226, -0.71837268],\n",
       "        [-0.13463518, -0.40077374, -0.77812761, -0.40760688, -0.22277304]]),\n",
       " 'action': array([[-0.32848067, -0.71076631,  0.33065364],\n",
       "        [-0.05175279,  0.36956034, -0.96124512],\n",
       "        [ 0.50680347, -0.75081392,  0.264312  ],\n",
       "        ...,\n",
       "        [ 0.85193194,  0.8514727 , -0.59952989],\n",
       "        [ 0.42420719, -0.09306683,  0.68725738],\n",
       "        [ 0.61809302, -0.99855857,  0.23421253]]),\n",
       " 'reward': array([-0.02114525, -0.06324221,  0.23084867, ...,  0.18275839,\n",
       "        -0.03419816,  0.39784407]),\n",
       " 'done': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'terminal': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'info': {},\n",
       " 'pscore': array([[0.17925664, 0.17925664, 0.17925664],\n",
       "        [0.05169203, 0.05169203, 0.05169203],\n",
       "        [0.29981178, 0.29981178, 0.29981178],\n",
       "        ...,\n",
       "        [0.0430945 , 0.0430945 , 0.0430945 ],\n",
       "        [0.2940625 , 0.2940625 , 0.2940625 ],\n",
       "        [0.32477468, 0.32477468, 0.32477468]]),\n",
       " 'behavior_policy': 'sac_sigma_1.0',\n",
       " 'dataset_id': 0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "オフライン強化学習やオフ方策評価 (OPE) に関しては[examples/quickstart/basic/basic_synthetic_continuous_basic.ipynb](https://github.com/hakuhodo-technologies/scope-rl/blob/main/examples/quickstart/basic/basic_synthetic_continuous_basic.ipynb)を参照してください．\n",
    "\n",
    "オフライン強化学習 (OPE) や オフ方策評価 (OPS) に関する発展的なトピックは[examples/quickstart/basic/basic_synthetic_continuous_advanced.ipynb](https://github.com/hakuhodo-technologies/scope-rl/blob/main/examples/quickstart/basic/basic_synthetic_continuous_advanced.ipynb)を参照してください．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 複数のデータ収集方策方策やランダムシードによるログデータの収集\n",
    "最後に，複数のデータ収集方策とランダムシードを用いてログデータを収集する際の効率的な実装方法を紹介します．\n",
    "\n",
    "離散行動の場合を紹介しますが，連続行動の場合も同様に扱うことができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 離散行動空間に対する標準的な環境\n",
    "env = gym.make(\"BasicEnv-discrete-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# いくつかのデータ収集方策を定義\n",
    "behavior_policy_01 = EpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.1,  # ランダム行動を選択する確率\n",
    "    name=\"ddqn_eps_0.1\",\n",
    "    random_state=random_state,\n",
    ")\n",
    "behavior_policy_03 = EpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.3,  # ランダム行動を選択する確率\n",
    "    name=\"ddqn_eps_0.3\",\n",
    "    random_state=random_state,\n",
    ")\n",
    "behavior_policy_05 = EpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.5,  # ランダム行動を選択する確率\n",
    "    name=\"ddqn_eps_0.5\",\n",
    "    random_state=random_state,\n",
    ")\n",
    "behavior_policy_07 = EpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.7,  # ランダム行動を選択する確率\n",
    "    name=\"ddqn_eps_0.7\",\n",
    "    random_state=random_state,\n",
    ")\n",
    "behavior_policies = [behavior_policy_01, behavior_policy_03, behavior_policy_05, behavior_policy_07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データクラスの初期化\n",
    "dataset = SyntheticDataset(\n",
    "    env=env,\n",
    "    max_episode_steps=env.step_per_episode,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_datasets = dataset.obtain_episodes(\n",
    "    behavior_policies=behavior_policies,\n",
    "    n_datasets=2,  # random_stateの数\n",
    "    n_trajectories=10000, \n",
    "    obtain_info=False,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 100000,\n",
       " 'n_trajectories': 10000,\n",
       " 'step_per_trajectory': 10,\n",
       " 'action_type': 'discrete',\n",
       " 'n_actions': 10,\n",
       " 'action_dim': None,\n",
       " 'action_meaning': None,\n",
       " 'action_keys': None,\n",
       " 'state_dim': 5,\n",
       " 'state_keys': None,\n",
       " 'state': array([[ 0.46692103, -0.60091272,  0.12748286,  0.10612129,  0.62719618],\n",
       "        [ 0.00305434,  0.25886564,  0.94683458, -0.18441597, -0.04974207],\n",
       "        [-0.13005656, -0.04117723,  0.18071338, -0.53347445,  0.81494626],\n",
       "        ...,\n",
       "        [ 0.0840951 , -0.18714296,  0.31295643, -0.82369983,  0.42600749],\n",
       "        [ 0.64171577,  0.10529459,  0.17897809, -0.2985224 ,  0.67525191],\n",
       "        [ 0.39900535,  0.04439272, -0.68787737, -0.60115584,  0.06527166]]),\n",
       " 'action': array([6, 6, 4, ..., 8, 4, 6]),\n",
       " 'reward': array([ 0.85571015,  0.80607969,  0.83013847, ..., -0.04520555,\n",
       "         0.78231063,  0.75780294]),\n",
       " 'done': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'terminal': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'info': {},\n",
       " 'pscore': array([0.91, 0.91, 0.91, ..., 0.01, 0.91, 0.91]),\n",
       " 'behavior_policy': 'ddqn_eps_0.1',\n",
       " 'dataset_id': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_dataset = logged_datasets.get(behavior_policy_name=behavior_policies[0].name, dataset_id=0)\n",
    "logged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数のデータを用いたオフライン強化学習やオフ方策評価 (OPE) に関しては[examples/quickstart/basic/basic_synthetic_discrete_multiple.ipynb](https://github.com/hakuhodo-technologies/scope-rl/blob/main/examples/quickstart/basic/basic_synthetic_discrete_multiple.ipynb)（離散行動空間），[examples/quickstart/basic/basic_synthetic_continuous_multiple.ipynb](https://github.com/hakuhodo-technologies/scope-rl/blob/main/examples/quickstart/basic/basic_synthetic_continuous_multiple.ipynb)（連続行動空間）を参照してください．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- Yuta Saito, Shunsuke Aihara, Megumi Matsutani, and Yusuke Narita. \\\n",
    "\"Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible Off-Policy Evaluation.\", 2021.\n",
    "\n",
    "- Takuma Seno and Michita Imai. \\\n",
    "\"d3rlpy: An Offline Deep Reinforcement Library.\", 2021.\n",
    "\n",
    "- Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. \\\n",
    "\"Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.\" 2018.\n",
    "\n",
    "- Di Wu, Xiujun Chen, Xun Yang, Hao Wang, Qing Tan, Xiaoxun Zhang, Jian Xu, and Kun Gai. \\\n",
    "\"Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising.\", 2018.\n",
    "\n",
    "- Jun Zhao, Guang Qiu, Ziyu Guan, Wei Zhao, and Xiaofei He. \\\n",
    "\"Deep Reinforcement Learning for Sponsored Search Real-time Bidding.\", 2018.\n",
    "\n",
    "- Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. \\\n",
    "\"OpenAI Gym.\", 2016.\n",
    "\n",
    "- Hado van Hasselt, Arthur Guez, and David Silver. \\\n",
    "\"Deep Reinforcement Learning with Double Q-learning.\", 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "70404ee114725fce8ed9e697d67827f8546c678889944e6d695790702cbfe1f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
